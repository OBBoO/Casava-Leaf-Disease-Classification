{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Input, BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.experimental import CosineDecay\n",
    "from tensorflow.keras.applications import EfficientNetB5, EfficientNetB3, EfficientNetB4\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from tensorflow.keras.layers.experimental.preprocessing import RandomRotation,RandomZoom\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tensorflow.keras import layers\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# Constants to access inputs\n",
    "INPUT_PATH = \"../input/cassava-leaf-disease-classification/\"\n",
    "MYFILES_PATH = \"../input/trainedmodels/\"\n",
    "EFFICIENTNET_PATH = \"../input/efficientnetb4/efficientnetb4_notop.h5\"\n",
    "TEST_IMAGES_PATH = INPUT_PATH + 'test_images/'\n",
    "TRAINING_IMAGES_PATH = INPUT_PATH + '/train_images/'\n",
    "TRAINING_LABEL_PATH = INPUT_PATH + 'train.csv'\n",
    "IMAGE_SIZE = {\n",
    "    'height':512,\n",
    "    'width':512,\n",
    "    'channels':3\n",
    "}\n",
    "LABEL_MAPPING_FILE_PATH = INPUT_PATH+'label_num_to_disease_map.json'\n",
    "BATCH_SIZE = 128\n",
    "NUM_CLASSES = 5\n",
    "MODEL_NAME = \"modelB5Noisy2.15-0.902.h5\"\n",
    "MODEL_WEIGHTS_NAME = \"weights_modelB5Noisy2.15-0.902.h5\"\n",
    "#NUM_EPOCHS=24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping = json.load(open(LABEL_MAPPING_FILE_PATH))\n",
    "df_train = pd.read_csv(TRAINING_LABEL_PATH)\n",
    "df_train['label_description'] = df_train.apply(lambda x : label_mapping.get(str(x['label']),\"NA\"),axis=1)\n",
    "df_train = df_train.astype({'label': 'str'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_train_test_dataframes(df,test_size,stratified:bool):\n",
    "    \n",
    "    if stratified:\n",
    "        strat = df.loc[:,['label']]\n",
    "    else:\n",
    "        strat = None\n",
    "        \n",
    "    return train_test_split(df.loc[:,['image_id','label','label_description']],df.loc[:,['label']],test_size = test_size,stratify = strat,random_state=94)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df,X_validation_df,y_train,y_validation = build_train_test_dataframes(df_train,0.1,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = data_generator.flow_from_dataframe(dataframe=X_train_df,x_col=\"image_id\",y_col=\"label\",classes=[\"0\",\"1\",\"2\",\"3\",\"4\"],\n",
    "                                                    directory = TRAINING_IMAGES_PATH,target_size=(IMAGE_SIZE[\"height\"],IMAGE_SIZE[\"width\"]),\n",
    "                                                    color_mode=\"rgb\",class_mode=\"categorical\",batch_size=BATCH_SIZE,validation_filenames=False,shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_generator = data_generator.flow_from_dataframe(dataframe=X_validation_df,x_col=\"image_id\",y_col='label',classes=[\"0\",\"1\",\"2\",\"3\",\"4\"],\n",
    "                                                    directory = TRAINING_IMAGES_PATH,target_size=(IMAGE_SIZE[\"height\"],IMAGE_SIZE[\"width\"]),\n",
    "                                                    color_mode=\"rgb\",class_mode=\"categorical\",batch_size=BATCH_SIZE,validation_filenames=False,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALIDATION=validation_generator.n//validation_generator.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path):\n",
    "    model = tf.keras.models.load_model(model_path,compile=False)",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    \n",
    "    data_augmentation = Sequential(\n",
    "    [\n",
    "        preprocessing.RandomRotation(factor=0.1),\n",
    "        #preprocessing.RandomTranslation(height_factor=0.1, width_factor=0.1),\n",
    "        preprocessing.RandomFlip(),\n",
    "        preprocessing.RandomZoom((-0.2, 0.2)),\n",
    "        preprocessing.RandomContrast(factor=0.2),\n",
    "    ],name=\"data_augmentation\",)\n",
    "    \n",
    "    inputs = layers.Input(shape=(IMAGE_SIZE[\"height\"],IMAGE_SIZE[\"width\"], 3))\n",
    "    x = data_augmentation(inputs)\n",
    "    x = layers.experimental.preprocessing.Rescaling(1./255)(x)\n",
    "    backbone_model = EfficientNetB4(include_top=False,weights=None,input_tensor=x,drop_connect_rate=0.4)\n",
    "    x = backbone_model(x, training=False)\n",
    "    \n",
    "    #We freeze the pretrained weights\n",
    "    #backbone_model.trainable = False\n",
    "    \n",
    "    x = layers.GlobalAveragePooling2D(name=\"avg_pool\")(backbone_model.output)\n",
    "    x = layers.BatchNormalization(name=\"BN_out1\",trainable=False)(x)\n",
    "    #x = layers.Dense(768,activation='relu',name=\"FC_out1\")(x)\n",
    "    x = layers.Dropout(0.4,name=\"dropout_layer\")(x)\n",
    "    outputs = layers.Dense(NUM_CLASSES,activation=\"softmax\",name=\"output_prediction\")(x)\n",
    "    \n",
    "    model = Model(inputs, outputs,name=\"CassavaAugmentedEfficientNetB4TrainedOnNoisy\")\n",
    "    \n",
    "    initial_learning_rate = 1e-4\n",
    "    #decay_steps = int(STEP_SIZE_TRAIN)*NUM_EPOCHS\n",
    "    #cosine_decay = CosineDecay(initial_learning_rate=initial_learning_rate,decay_steps=decay_steps, alpha=0.1)\n",
    "    #lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    #                initial_learning_rate,\n",
    "    #                decay_steps=600,\n",
    "    #                decay_rate=0.96,\n",
    "    #                staircase=True)\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "    model.compile(\n",
    "        \n",
    "        optimizer=optimizer,\n",
    "        loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.3),\n",
    "        metrics=[\"categorical_accuracy\"]\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(MYFILES_PATH+MODEL_WEIGHTS_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def finetune_model():\n",
    "    \n",
    "#    initial_learning_rate = 1e-7\n",
    "    #decay_steps = int(STEP_SIZE_TRAIN)*NUM_EPOCHS\n",
    "    #cosine_decay = CosineDecay(initial_learning_rate=initial_learning_rate,decay_steps=decay_steps, alpha=0.3)\n",
    "    #lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    #                initial_learning_rate,\n",
    "    #                decay_steps=600,\n",
    "    #                decay_rate=0.96,\n",
    "    #                staircase=True)\n",
    "\n",
    "#    optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "#    model.compile(\n",
    "\n",
    "#        optimizer=optimizer,\n",
    "#        loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.3),\n",
    "#        metrics=[\"accuracy\"]\n",
    "#    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finetune_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.argmax(model.predict(validation_generator,verbose=1),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_validation_df[\"predictions\"]=predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_validation_df = X_validation_df.astype({\"label\":int})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_validation_df[\"label_description\"].hist(xrot=90,figsize=(12,9))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(X_validation_df[\"label\"],X_validation_df[\"predictions\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report=classification_report(X_validation_df[\"label\"],X_validation_df[\"predictions\"],target_names=[\"Cassava Bacterial Blight (CBB)\",\"Cassava Brown Streak Disease (CBSD)\",\"Cassava Green Mottle (CGM)\",\"Cassava Mosaic Disease (CMD)\",\"Healthy\"])\n",
    "\n",
    "print(report)                                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(classification_report(X_validation_df[\"label\"],X_validation_df[\"predictions\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------- GRADCAM ------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_array(img_path, size):\n",
    "    # `img` is a PIL image of size 299x299\n",
    "    img = keras.preprocessing.image.load_img(img_path, target_size=size)\n",
    "    # `array` is a float32 Numpy array of shape (299, 299, 3)\n",
    "    array = keras.preprocessing.image.img_to_array(img)\n",
    "    # We add a dimension to transform our array into a \"batch\"\n",
    "    # of size (1, 299, 299, 3)\n",
    "    array = np.expand_dims(array, axis=0)\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, classifier_layer_names):\n",
    "    # First, we create a model that maps the input image to the activations\n",
    "    # of the last conv layer\n",
    "    last_conv_layer = model.get_layer(last_conv_layer_name)\n",
    "    last_conv_layer_model = keras.Model(model.inputs, last_conv_layer.output)\n",
    "\n",
    "    # Second, we create a model that maps the activations of the last conv\n",
    "    # layer to the final class predictions\n",
    "    classifier_input = keras.Input(shape=last_conv_layer.output.shape[1:])\n",
    "    x = classifier_input\n",
    "    for layer_name in classifier_layer_names:\n",
    "        x = model.get_layer(layer_name)(x)\n",
    "    classifier_model = keras.Model(classifier_input, x)\n",
    "\n",
    "    # Then, we compute the gradient of the top predicted class for our input image\n",
    "    # with respect to the activations of the last conv layer\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Compute activations of the last conv layer and make the tape watch it\n",
    "        last_conv_layer_output = last_conv_layer_model(img_array)\n",
    "        tape.watch(last_conv_layer_output)\n",
    "        # Compute class predictions\n",
    "        preds = classifier_model(last_conv_layer_output)\n",
    "        top_pred_index = tf.argmax(preds[0])\n",
    "        top_class_channel = preds[:, top_pred_index]\n",
    "\n",
    "    # This is the gradient of the top predicted class with regard to\n",
    "    # the output feature map of the last conv layer\n",
    "    grads = tape.gradient(top_class_channel, last_conv_layer_output)\n",
    "\n",
    "    # This is a vector where each entry is the mean intensity of the gradient\n",
    "    # over a specific feature map channel\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "    # We multiply each channel in the feature map array\n",
    "    # by \"how important this channel is\" with regard to the top predicted class\n",
    "    last_conv_layer_output = last_conv_layer_output.numpy()[0]\n",
    "    pooled_grads = pooled_grads.numpy()\n",
    "    for i in range(pooled_grads.shape[-1]):\n",
    "        last_conv_layer_output[:, :, i] *= pooled_grads[i]\n",
    "\n",
    "    # The channel-wise mean of the resulting feature map\n",
    "    # is our heatmap of class activation\n",
    "    heatmap = np.mean(last_conv_layer_output, axis=-1)\n",
    "\n",
    "    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n",
    "    heatmap = np.maximum(heatmap, 0) / np.max(heatmap)\n",
    "    return heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_conv_layer_name = \"top_activation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_layer_names = [\n",
    "    \"avg_pool\",\n",
    "    \"BN_out1\",\n",
    "    \"dropout_layer\",\n",
    "    \"output_prediction\"    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_test_path = TRAINING_IMAGES_PATH+X_validation_df['image_id'].values[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(image_test_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_test_array = get_img_array(image_test_path,size=(512,512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(image_test_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap = make_gradcam_heatmap(image_test_array, model, last_conv_layer_name, classifier_layer_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.expand_dims(heatmap, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = np.zeros((16,16,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m[:,:,0]=heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_heatmap = keras.preprocessing.image.array_to_img(m)\n",
    "mj_heatmap = m_heatmap.resize((512,512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mj_heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    heatmap = np.uint8(255 * heatmap)\n",
    "\n",
    "    # We use jet colormap to colorize heatmap\n",
    "    jet = cm.get_cmap(\"jet\")\n",
    "\n",
    "    # We use RGB values of the colormap\n",
    "    jet_colors = jet(np.arange(256))[:, :3]\n",
    "    jet_heatmap = jet_colors[heatmap]\n",
    "\n",
    "    # We create an image with RGB colorized heatmap\n",
    "    jet_heatmap = keras.preprocessing.image.array_to_img(jet_heatmap)\n",
    "    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n",
    "    #jet_heatmap = keras.preprocessing.image.img_to_array(jet_heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def super_imposed_image(img_path,heatmap,save_path=\"superimposed.jpg\"):\n",
    "    \n",
    "    # We load the original image\n",
    "    img = keras.preprocessing.image.load_img(img_path)\n",
    "    img = keras.preprocessing.image.img_to_array(img)\n",
    "    m = np.zeros((16,16,3))\n",
    "    m[:,:,0]=heatmap\n",
    "    # We rescale heatmap to a range 0-255\n",
    "    #heatmap = np.uint8(255 * heatmap)\n",
    "\n",
    "    # We use jet colormap to colorize heatmap\n",
    "    #jet = cm.get_cmap(\"jet\")\n",
    "\n",
    "    # We use RGB values of the colormap\n",
    "    #jet_colors = jet(np.arange(256))[:, :3]\n",
    "    #jet_heatmap = jet_colors[heatmap]\n",
    "    #print(jet_heatmap)\n",
    "    # We create an image with RGB colorized heatmap\n",
    "    jet_heatmap = keras.preprocessing.image.array_to_img(m)\n",
    "    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n",
    "    jet_heatmap = keras.preprocessing.image.img_to_array(jet_heatmap)\n",
    "    # Superimpose the heatmap on original image\n",
    "    superimposed_img = jet_heatmap + 0.6*img\n",
    "    #superimposed_img = np.maximum(jet_heatmap,img)\n",
    "    superimposed_img = keras.preprocessing.image.array_to_img(superimposed_img)\n",
    "\n",
    "    # Save the superimposed image\n",
    "    #save_path = \"elephant_cam.jpg\"\n",
    "    superimposed_img.save(save_path)\n",
    "\n",
    "    # Display Grad CAM\n",
    "    display(Image(save_path))\n",
    "    return superimposed_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_image = super_imposed_image(image_test_path,heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
